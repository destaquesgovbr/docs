---
date: 2026-02-26
authors:
  - nitai
categories:
  - Arquitetura
  - Airflow
  - RefatoraÃ§Ã£o
title: "6 dias, 36 PRs, 3 repos novos: desmembrando o monolito data-platform"
hide:
  - toc
---

# ğŸ—ï¸ 6 dias, 36 PRs, 3 repos novos: desmembrando o monolito data-platform

Na quinta passada, o data-platform era um monolito: scrapers, DAGs, sync de datasets e integraÃ§Ã£o com LLM â€” tudo num repo sÃ³ ğŸ˜…. Hoje, uma semana depois, cada domÃ­nio vive no seu repo, deploya suas prÃ³prias DAGs e tem autonomia de release. Pelo caminho, o servidor ActivityPub ganhou pipeline de publicaÃ§Ã£o e entramos no Fediverso ğŸŒ. Foram **36 PRs mergeados** em **9 repos**, **3 repos novos** criados, **4 issues fechadas** e **5 avanÃ§adas** â€” tudo sem parar o pipeline em produÃ§Ã£o.

<!-- more -->

Este post conta essa histÃ³ria: as decisÃµes, os erros, as esperas de 20 minutos â³ e o momento em que percebemos que estÃ¡vamos codificando um padrÃ£o novo.

---

## ğŸ—ºï¸ Contexto: o que Ã© o DGB

O [Destaques Gov BR](https://github.com/destaquesgovbr) agrega notÃ­cias de ~158 Ã³rgÃ£os do governo federal. Um scraper coleta as publicaÃ§Ãµes, um pipeline enriquece via LLM (classificaÃ§Ã£o temÃ¡tica, embeddings), e um portal pÃºblico exibe tudo com busca semÃ¢ntica. A infraestrutura roda na GCP: Cloud SQL (PostgreSQL), Cloud Composer (Airflow), Cloud Run e Typesense.

AtÃ© a semana passada, quase toda essa lÃ³gica vivia em um Ãºnico repositÃ³rio: `data-platform`. ğŸ‘€

---

## â˜€ï¸ Domingo: scraper no Airflow (e a frustraÃ§Ã£o que mudou a arquitetura)

Tudo comeÃ§ou com a issue [`data-platform#57`](https://github.com/destaquesgovbr/data-platform/issues/57) â€” "Migrar Scraper para Airflow com DAG por Ã“rgÃ£o". O scraping rodava via GitHub Actions, sequencial, uma vez por dia. O plano ([`MIGRAR-SCRAPER-AIRFLOW.md`](https://github.com/destaquesgovbr/data-platform/blob/main/_plan/MIGRAR-SCRAPER-AIRFLOW.md)) desenhava DAGs dinÃ¢micas, uma por agÃªncia, com schedule de 15 minutos.

Os primeiros PRs foram direto ao ponto: [`data-platform#76`](https://github.com/destaquesgovbr/data-platform/pull/76) migrou o scraper para o Airflow. E aÃ­ comeÃ§aram os fixes â€” [`#77`](https://github.com/destaquesgovbr/data-platform/pull/77), [`#78`](https://github.com/destaquesgovbr/data-platform/pull/78), [`#79`](https://github.com/destaquesgovbr/data-platform/pull/79) â€” cada um corrigindo algo que sÃ³ aparece em produÃ§Ã£o: formato do `requirements.txt`, ordem dos argumentos do `gsutil rsync`, dependÃªncias faltando ğŸ¤¦. O Composer Ã© implacÃ¡vel: cada atualizaÃ§Ã£o de requirements leva 10-20 minutos. Deploy, esperar, descobrir o erro, fix, esperar de novo.

Foi justamente nessas esperas de 20 minutos que veio a percepÃ§Ã£o mais importante da semana ğŸ’¡: **instalar o scraper inteiro como dependÃªncia do Composer Ã© frÃ¡gil**. O Composer deveria orquestrar, nÃ£o executar. O plano [`SCRAPER-CLOUD-RUN-API.md`](https://github.com/destaquesgovbr/data-platform/blob/main/_plan/SCRAPER-CLOUD-RUN-API.md) redesenhou tudo:

```mermaid
flowchart LR
    subgraph Composer["â˜ï¸ Cloud Composer (Airflow)"]
        DAG["ğŸ”„ DAG scrape_mec\n2 linhas de HTTP"]
    end
    subgraph CloudRun["ğŸ³ Cloud Run (scraper-api)"]
        API["POST /scrape/agencies\nScrapeManager.run()\nâ†’ PostgreSQL"]
    end
    DAG -->|"HTTP POST\nBearer IAM ğŸ”"| API
```

DAGs viram chamadas HTTP de duas linhas. Workers do Airflow ficam leves. Scraper roda em container isolado com scale-to-zero ğŸ¯. Um PR no data-platform ([`#80`](https://github.com/destaquesgovbr/data-platform/pull/80)) e outro no infra ([`infra#78`](https://github.com/destaquesgovbr/infra/pull/78)) para o Terraform, e a nova arquitetura estava rodando.

---

## ğŸ“¦ Segunda: nasce o repo `scraper`

Com a API funcionando no Cloud Run, o scraper jÃ¡ nÃ£o pertencia ao data-platform. O plano [`EXTRAIR-SCRAPER-REPO.md`](https://github.com/destaquesgovbr/data-platform/blob/main/_plan/EXTRAIR-SCRAPER-REPO.md) mapeou a cirurgia: novo repo, Workload Identity Federation, deploy de DAGs em subdiretÃ³rio separado no bucket GCS do Composer.

ğŸ†• **Novo repo**: [`destaquesgovbr/scraper`](https://github.com/destaquesgovbr/scraper)

A extraÃ§Ã£o exigiu mudanÃ§as coordenadas em trÃªs repos simultÃ¢neos. No infra: WIF binding ([`infra#82`](https://github.com/destaquesgovbr/infra/pull/82)), ajuste de concorrÃªncia ([`infra#80`](https://github.com/destaquesgovbr/infra/pull/80)), remoÃ§Ã£o do pandas do Composer ([`infra#83`](https://github.com/destaquesgovbr/infra/pull/83)). No data-platform: migrar DAGs para subdiretÃ³rio ([`#81`](https://github.com/destaquesgovbr/data-platform/pull/81)), remover cÃ³digo extraÃ­do ([`#82`](https://github.com/destaquesgovbr/data-platform/pull/82)), limpar step de requirements ([`#83`](https://github.com/destaquesgovbr/data-platform/pull/83)). No scraper: CLAUDE.md documentando tudo ([`scraper#1`](https://github.com/destaquesgovbr/scraper/pull/1)).

O padrÃ£o ficou claro: **cada repo deploya suas DAGs num subdiretÃ³rio prÃ³prio do Composer via `gsutil rsync`**. O data-platform usa `data-platform/`, o scraper usa `scraper/`. Simples, mas precisava funcionar com Workload Identity Federation, permissÃµes GCS e GitHub Actions â€” tudo coordenado ğŸ¤.

---

## ğŸ”§ TerÃ§a: reusable workflows, data-publishing e o padrÃ£o que virou skill

### â™»ï¸ DRY no deploy

Com dois repos deployando DAGs no mesmo bucket, copiar o workflow de deploy era questÃ£o de tempo. Antes de ter um terceiro, criamos o reusable workflow ([`reusable-workflows#3`](https://github.com/destaquesgovbr/reusable-workflows/pull/3)): qualquer repo chama com 2-3 parÃ¢metros e ganha deploy no Composer. A adoÃ§Ã£o foi imediata â€” [`data-platform#85`](https://github.com/destaquesgovbr/data-platform/pull/85), [`scraper#2`](https://github.com/destaquesgovbr/scraper/pull/2) e [`scraper#3`](https://github.com/destaquesgovbr/scraper/pull/3) migraram no mesmo dia.

### ğŸ“¤ Segundo desmembramento: data-publishing

O plano [`PLAN-data-publishing-migration.md`](https://github.com/destaquesgovbr/data-platform/blob/main/_plan/PLAN-data-publishing-migration.md) extraiu a DAG de sync PostgreSQL â†’ HuggingFace para um repo prÃ³prio. Isso resolveu, por um caminho inesperado, a issue [`data-platform#28`](https://github.com/destaquesgovbr/data-platform/issues/28) â€” que pedia KubernetesPodOperator para isolar dependÃªncias pesadas. A soluÃ§Ã£o acabou sendo mais elegante: repo dedicado com plugins no Composer, sem Kubernetes âœ¨.

ğŸ†• **Novo repo**: [`destaquesgovbr/data-publishing`](https://github.com/destaquesgovbr/data-publishing)

Os PRs de finalizaÃ§Ã£o limparam o data-platform: remoÃ§Ã£o da DAG de teste ([`#86`](https://github.com/destaquesgovbr/data-platform/pull/86)), remoÃ§Ã£o do sync HuggingFace ([`#87`](https://github.com/destaquesgovbr/data-platform/pull/87)), WIF no infra ([`infra#85`](https://github.com/destaquesgovbr/infra/pull/85)), e atualizaÃ§Ã£o da documentaÃ§Ã£o ([`docs#31`](https://github.com/destaquesgovbr/docs/pull/31)).

### ğŸ§  O momento meta: codificando o padrÃ£o

Com trÃªs repos seguindo o mesmo padrÃ£o de DAGs (scraper, data-publishing, activitypub-server), ficou claro que tÃ­nhamos uma convenÃ§Ã£o madura. Em vez de deixar esse conhecimento implÃ­cito, codificamos tudo numa **skill do Claude Code** ğŸ¤–:

[`data-platform#88`](https://github.com/destaquesgovbr/data-platform/pull/88) â€” `/criar-dag`, um guia de ~470 linhas que inclui: referÃªncia completa da arquitetura Airflow do projeto (connections, schema PostgreSQL, pipeline de dados), templates para plugin + DAG + workflow + testes, e passo-a-passo de setup na infra.

ComeÃ§amos a semana criando DAGs manualmente. Terminamos codificando o padrÃ£o para que DAGs futuras nasÃ§am prontas ğŸš€.

---

## ğŸŒ O outro trilho: ActivityPub e o Fediverso

Em paralelo Ã  decomposiÃ§Ã£o do monolito, o [`activitypub-server`](https://github.com/destaquesgovbr/activitypub-server) (criado em 13/fev) ganhava sua peÃ§a final: a integraÃ§Ã£o com o pipeline de dados. O servidor jÃ¡ existia, mas como ele saberia que existem notÃ­cias novas? ğŸ¤”

A resposta: uma DAG no Airflow. O PR central ([`activitypub-server#1`](https://github.com/destaquesgovbr/activitypub-server/pull/1) â€” Phase 6) adicionou coluna `news_payload JSONB` na fila de publicaÃ§Ã£o e a DAG `federation_publish` que roda a cada 10 minutos. No infra, trÃªs PRs prepararam o terreno: remoÃ§Ã£o da variÃ¡vel PORT reservada ([`infra#79`](https://github.com/destaquesgovbr/infra/pull/79)), fix de conectividade ([`infra#81`](https://github.com/destaquesgovbr/infra/pull/81)) e secrets para o banco ([`infra#84`](https://github.com/destaquesgovbr/infra/pull/84)).

Com a DAG em produÃ§Ã£o, veio o ciclo clÃ¡ssico de observar e otimizar ğŸ”. Em 24 horas, seis PRs de ajuste: batch loop ([`#2`](https://github.com/destaquesgovbr/activitypub-server/pull/2)), max_active_runs=1 ([`#3`](https://github.com/destaquesgovbr/activitypub-server/pull/3)), batch INSERT ([`#5`](https://github.com/destaquesgovbr/activitypub-server/pull/5)), migraÃ§Ã£o para reusable workflow ([`#6`](https://github.com/destaquesgovbr/activitypub-server/pull/6)), ambiente local com Astro CLI ([`#7`](https://github.com/destaquesgovbr/activitypub-server/pull/7)) e remoÃ§Ã£o do limite de fila ([`#8`](https://github.com/destaquesgovbr/activitypub-server/pull/8)). A sequÃªncia batch loop â†’ max_active_runs â†’ batch INSERT Ã© o tipo de histÃ³ria que nenhum plano prevÃª â€” e tÃ¡ tudo bem ğŸ˜„.

O Astro CLI ([`#7`](https://github.com/destaquesgovbr/activitypub-server/pull/7)) merece nota: avanÃ§a a issue [`data-platform#42`](https://github.com/destaquesgovbr/data-platform/issues/42) e cria o padrÃ£o de ambiente Airflow local que serÃ¡ replicado nos outros repos.

---

## ğŸ® Organizando a sala de controle

Enquanto os repos de dados eram decompostos, o repo [`project`](https://github.com/destaquesgovbr/project) ganhava forma como sala de controle do DGB. A skill `/enviar-telegram` ([`project#1`](https://github.com/destaquesgovbr/project/pull/1)) foi a primeira a chegar â€” permite enviar resumos de sprint, daily e backlog direto para o canal da equipe no Telegram ğŸ“².

E no portal, a documentaÃ§Ã£o dos feeds RSS/Atom/JSON ([`portal#80`](https://github.com/destaquesgovbr/portal/pull/80)) finalizou uma peÃ§a que faltava para consumidores externos da API.

---

## ğŸ”€ O antes e depois

### Antes (20/fev)

```mermaid
block-beta
    columns 1
    block:monolito["ğŸ“¦ data-platform (monolito)"]
        columns 3
        scrapers["ğŸ•·ï¸ scrapers/"]
        api["âš¡ api.py"]
        dags["ğŸ“‹ dags/ (TODAS)"]
        managers["ğŸ’¾ managers/"]
        cogfy["ğŸ¤– cogfy/"]
        typesense["ğŸ” typesense/"]
    end
```

### Depois (26/fev)

```mermaid
block-beta
    columns 3
    scraper["ğŸ•·ï¸ scraper\nCloud Run API + DAGs"]:1
    publishing["ğŸ“¤ data-publishing\nSync PG â†’ HuggingFace"]:1
    activitypub["ğŸŒ activitypub-server\nFederaÃ§Ã£o + DAG"]:1
    platform["âš™ï¸ data-platform\nCore: Cogfy, Typesense"]:1
    workflows["â™»ï¸ reusable-workflows\nCI/CD compartilhado"]:1
    infra["ğŸ—ï¸ infra\nTerraform, IAM, WIF"]:1
```

Cada repo tem seu prÃ³prio `CLAUDE.md`, deploya suas DAGs num subdiretÃ³rio do Composer, usa o reusable workflow e tem autonomia completa de release âœ….

---

## âœ… Issues resolvidas pelo caminho

Uma surpresa positiva da semana: ao revisar o backlog, descobrimos que vÃ¡rias issues mapeadas foram resolvidas como efeito colateral das refatoraÃ§Ãµes â€” nenhuma atacada diretamente ğŸ¯.

### ğŸŸ¢ Fechadas

| Issue | TÃ­tulo | Como foi resolvida |
|-------|--------|-------------------|
| [`data-platform#57`](https://github.com/destaquesgovbr/data-platform/issues/57) | Migrar Scraper para Airflow | ImplementaÃ§Ã£o direta â†’ extraÃ§Ã£o para repo `scraper` |
| [`data-platform#28`](https://github.com/destaquesgovbr/data-platform/issues/28) | Sync HF em ambiente isolado | ExtraÃ§Ã£o para `data-publishing` com plugins (sem K8s!) |
| [`data-platform#22`](https://github.com/destaquesgovbr/data-platform/issues/22) | DAG de exportaÃ§Ã£o HuggingFace | Refatorada e migrada para `data-publishing` |
| [`docs#30`](https://github.com/destaquesgovbr/docs/issues/30) | Criar repo data-science | Repo criado em 13/fev com 14 issues de pesquisa |

### ğŸŸ¡ AvanÃ§adas

| Issue | TÃ­tulo | Progresso |
|-------|--------|-----------|
| [`data-platform#42`](https://github.com/destaquesgovbr/data-platform/issues/42) | Astro CLI para dev local | ~70% â€” padrÃ£o pronto no activitypub-server, falta replicar |
| [`data-platform#45`](https://github.com/destaquesgovbr/data-platform/issues/45) | Remover cÃ³digo morto HF | ~50% â€” falta limpar StorageAdapter |
| [`data-platform#73`](https://github.com/destaquesgovbr/data-platform/issues/73) | Monitoramento do scraper | ~30% â€” Airflow dÃ¡ visibilidade por DAG, faltam alertas |
| [`docs#15`](https://github.com/destaquesgovbr/docs/issues/15) | Documentar DAG sync HF | ~40% â€” atualizar docs com nova arquitetura |
| [`data-platform#64`](https://github.com/destaquesgovbr/data-platform/issues/64) | Campo `active` para agÃªncias | Habilitada via pause/unpause de DAGs no Airflow |

---

## ğŸ“Š NÃºmeros

| MÃ©trica | Valor |
|---------|-------|
| ğŸ”€ PRs mergeados | 36 |
| ğŸ“ Repos tocados | 9 |
| ğŸ†• Repos novos | 3 (scraper, data-publishing, data-science) |
| âœ… Issues fechadas | 4 |
| ğŸŸ¡ Issues avanÃ§adas | 5 |
| ğŸ“ Planos escritos | 4 |
| ğŸ¤– Skills criadas | 2 (/enviar-telegram, /criar-dag) |
| ğŸ“… Dias | 6 |

---

## ğŸ’¡ LiÃ§Ãµes

**1. ğŸ“‹ Planejar antes de codar.** Cada refatoraÃ§Ã£o teve um `_plan/*.md` com arquitetura alvo, sequÃªncia de migraÃ§Ã£o e critÃ©rios de verificaÃ§Ã£o. Nenhum plano sobreviveu intacto ao contato com produÃ§Ã£o, mas todos evitaram decisÃµes erradas que custariam horas.

**2. ğŸ”„ Migrar sem downtime Ã© uma sequÃªncia, nÃ£o um evento.** Criar novo â†’ validar â†’ pausar antigo â†’ remover. Sempre nessa ordem. Nunca quebramos o pipeline em produÃ§Ã£o.

**3. â™»ï¸ Reusable workflows sÃ£o multiplicadores.** Um workflow parametrizado economiza meia hora de configuraÃ§Ã£o em cada repo novo. Com trÃªs repos adotando em uma semana, jÃ¡ se pagou.

**4. ğŸ¯ Orquestrar, nÃ£o executar.** Mover execuÃ§Ã£o pesada para Cloud Run e manter DAGs leves (duas linhas de HTTP) foi a decisÃ£o de arquitetura mais impactante. Nasceu da frustraÃ§Ã£o com o Composer â€” Ã s vezes a melhor ideia vem enquanto vocÃª espera â³.

**5. ğŸ” O ciclo deploy-observar-otimizar Ã© inevitÃ¡vel.** Os PRs #2 a #8 do activitypub-server sÃ£o a prova: nenhum design prevÃª tudo. O importante Ã© que o ciclo seja rÃ¡pido.

**6. ğŸ¤– Codificar padrÃµes, nÃ£o sÃ³ usar.** Quando um padrÃ£o se repete trÃªs vezes, vale transformar em skill ou template. A `/criar-dag` nasceu depois de criarmos DAGs em trÃªs repos â€” agora o prÃ³ximo dev (ou o Claude Code) replica o padrÃ£o sozinho.

**7. ğŸ›ï¸ Boa arquitetura resolve problemas que vocÃª nem estava olhando.** Das quatro issues fechadas, nenhuma foi atacada diretamente. Todas caÃ­ram como efeito colateral de decisÃµes arquiteturais. Isso diz algo sobre o valor de refatorar com intenÃ§Ã£o.

---

*Todos os PRs, issues e planos estÃ£o linkados ao longo do texto. O cÃ³digo Ã© aberto â€” explore Ã  vontade ğŸ™Œ*
